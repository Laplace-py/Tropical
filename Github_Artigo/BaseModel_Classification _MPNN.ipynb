{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1661c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import standard packages for model training\n",
    "\n",
    "import tensorflow as T\n",
    "from tensorflow import *\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.losses import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as SK\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import io\n",
    "from utils import utils\n",
    "from utils.GPU import *\n",
    "commons = utils.Commons()\n",
    "ts_helper = utils.TS_Helper()\n",
    "ts_helper.model_type = ts_helper.Classification\n",
    "shap_helper = utils.Shap_Helper()\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import train, validation and test sets\n",
    "\n",
    "training = './data/Classification/T.cruzi/scaffold_split/train_fold_0.csv'\n",
    "validation = './data/Classification/T.cruzi/scaffold_split/valid_fold_1.csv'\n",
    "test = './data/Classification/T.cruzi/scaffold_split/test_fold_2.csv'\n",
    "TASK_START = 2\n",
    "NUM_TASKS = 1\n",
    "SMILES = \"SMILES\"\n",
    "train_dataset,y_train,train_smiles = commons.load_dataset(training,SMILES,TASK_START,NUM_TASKS)\n",
    "val_dataset,y_val,val_smiles = commons.load_dataset(validation,SMILES,TASK_START,NUM_TASKS)\n",
    "test_dataset,y_test,test_smiles = commons.load_dataset(test,SMILES,TASK_START,NUM_TASKS)\n",
    "\n",
    "#train_dataset.iloc[:,TASK_START] = list(map(lambda x: float(x), train_dataset.iloc[:,TASK_START]))\n",
    "#y_train = list(map(lambda x: float(x), y_train))\n",
    "\n",
    "#test_dataset.iloc[:,TASK_START] = list(map(lambda x: float(x), test_dataset.iloc[:,TASK_START]))\n",
    "#y_test = list(map(lambda x: float(x), y_test))\n",
    "#val_dataset.iloc[:,TASK_START].astype(float)\n",
    "#val_dataset.iloc[:,TASK_START] = [float(x) for x in val_dataset.iloc[:,TASK_START]]\n",
    "#y_val = [float(y) for y in y_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import atom and bond featurizers\n",
    "\n",
    "from utils.graphs import *\n",
    "\n",
    "X_train = graphs_from_smiles(train_dataset.iloc[:,NUM_TASKS].values)\n",
    "#print(train_dataset.iloc[:,NUM_TASKS].values)\n",
    "X_test = graphs_from_smiles(test_dataset.iloc[:,NUM_TASKS].values)\n",
    "\n",
    "X_val = graphs_from_smiles(val_dataset.iloc[:,NUM_TASKS].values)\n",
    " \n",
    "#molecule = molecule_from_smiles(train_dataset.iloc[8].SMILES)\n",
    "#graph = graph_from_molecule(molecule)\n",
    "# print(\"Graph (including self-loops):\")\n",
    "# print(\"\\tatom features\\t\", graph[0].shape)\n",
    "# print(\"\\tbond features\\t\", graph[1].shape)\n",
    "# print(\"\\tpair indices\\t\", graph[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47cd610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import parameters for batch, MPNN, loss and scorers\n",
    "\n",
    "batch_size =48\n",
    "dense_units = 50\n",
    "\n",
    "from utils.batch import *\n",
    "from utils.MPNN import *\n",
    "from utils.utils import *\n",
    "\n",
    "\n",
    "# parameters for train network\n",
    "\n",
    "def MPNNModel(atom_dim,\n",
    "    bond_dim,\n",
    "    batch_size=batch_size,\n",
    "    message_units=48,\n",
    "    message_steps=8,\n",
    "    num_attention_heads=16,\n",
    "    dense_units=dense_units):\n",
    "\n",
    "    atom_features = layers.Input((atom_dim), dtype=\"float32\", name=\"atom_features\")\n",
    "    bond_features = layers.Input((bond_dim), dtype=\"float32\", name=\"bond_features\")\n",
    "    pair_indices = layers.Input((2), dtype=\"int32\", name=\"pair_indices\")\n",
    "    molecule_indicator = layers.Input((), dtype=\"int32\", name=\"molecule_indicator\")\n",
    "\n",
    "    x = MessagePassing(message_units, message_steps)([atom_features, bond_features, pair_indices])\n",
    "    x = TransformerEncoderReadout(num_attention_heads, message_units, dense_units, batch_size)([x, molecule_indicator])\n",
    "    x = layers.Dense(10, activation=\"sigmoid\", kernel_regularizer=T.keras.regularizers.L2(0.05))(x)\n",
    "\n",
    "    \n",
    "    model = keras.Model(inputs=[atom_features, bond_features, pair_indices, molecule_indicator],\n",
    "        outputs=[x])\n",
    "    return model\n",
    "    \n",
    "optimizer = RMSprop(0.1, momentum=0.99)\n",
    "lr_metric = ts_helper.get_lr_metric(optimizer)   \n",
    "\n",
    "model = MPNNModel(atom_dim=X_train[0][0][0].shape[0], bond_dim=X_train[1][0][0].shape[0])\n",
    "model.compile(loss = ts_helper.classification_loss(ts_helper.BinaryCrossentropy,1), metrics=[lr_metric])   \n",
    "model.summary()\n",
    "T.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0d0455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Early stopping parameters\n",
    "\n",
    "train_model = MPNNDataset(X_train, y_train, batch_size)\n",
    "val_model = MPNNDataset(X_val, y_val, batch_size)\n",
    "test_model = MPNNDataset(X_test, y_test, batch_size)\n",
    "#print(train_dataset.unbatch())\n",
    "callbacks_list = [\n",
    "    ReduceLROnPlateau(monitor='loss', factor=0.5, patience=10, min_lr=0.000000001, verbose=1, mode='auto',cooldown=0),\n",
    "    #ModelCheckpoint(filepath=\"./models/fine_tuned_model2.tf\", monitor='val_loss', save_best_only=True, verbose=1, mode='auto'),\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, mode='min', verbose=1)]\n",
    "\n",
    "# parameters for train network\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(train_model,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data = val_model,                    \n",
    "                    callbacks = (callbacks_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da804fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot model history\n",
    "\n",
    "ts_helper.plot_history(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059e867d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Statistical characteristics of tasks\n",
    "THRESHOLD = 0.5\n",
    "print(ts_helper.model_type)\n",
    "\n",
    "ts_helper.get_modelStatsFor_Train_Test_Validation(model,X_train=train_model,y_train=y_train,X_test=test_model,y_test=y_test,X_val=val_model,y_val=y_val,tasks=NUM_TASKS,threshold=THRESHOLD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "305c663c06086012150402cb542001f2c1c554dcd7eca29927fc1d739b83f0a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
