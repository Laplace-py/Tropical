{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c80e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import standard packages for model training\n",
    "\n",
    "import tensorflow as T\n",
    "from tensorflow import *\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.losses import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as SK\n",
    "from sklearn.metrics import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import io\n",
    "from utils.GPU import *\n",
    "    \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6733772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Inport train, validation and test sets\n",
    "\n",
    "training = './data/random_split/train_fold_0.csv'\n",
    "validation = './data/random_split/valid_fold_0.csv'\n",
    "test = './data/random_split/test_fold_0.csv'\n",
    "\n",
    "# load training dataset\n",
    "train_dataset = pd.read_csv(training, delimiter=',', low_memory=False)\n",
    "\n",
    "# load validation dataset\n",
    "val_dataset = pd.read_csv(validation, delimiter=',', low_memory=False)\n",
    "\n",
    "# load test dataset\n",
    "test_dataset = pd.read_csv(test, delimiter=',', low_memory=False)\n",
    "\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import atom and bond featurizers\n",
    "\n",
    "from utils.graphs import *\n",
    "\n",
    "#select the numb of tasks here\n",
    "\n",
    "task_start = 2\n",
    "tasks= 6\n",
    "task_index = tasks + 2\n",
    "\n",
    "#Gennerate graphs from SMILES\n",
    "\n",
    "X_train = graphs_from_smiles(train_dataset.iloc[:,1].values)\n",
    "y_train = train_dataset.iloc[:,2:task_index].values\n",
    "\n",
    "X_test = graphs_from_smiles(test_dataset.iloc[:,1].values)\n",
    "y_test = test_dataset.iloc[:,2:task_index].values\n",
    "\n",
    "X_val = graphs_from_smiles(val_dataset.iloc[:,1].values)\n",
    "y_val = val_dataset.iloc[:,2:task_index].values\n",
    "\n",
    "#Test graph function\n",
    "\n",
    "molecule = molecule_from_smiles(train_dataset.iloc[8].SMILES)\n",
    "graph = graph_from_molecule(molecule)\n",
    "print(\"Graph (including self-loops):\")\n",
    "print(\"\\tatom features\\t\", graph[0].shape)\n",
    "print(\"\\tbond features\\t\", graph[1].shape)\n",
    "print(\"\\tpair indices\\t\", graph[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304de3d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import parameters for batch, MPNN, loss and scorers\n",
    "\n",
    "batch_size = 48\n",
    "dense_units = 50\n",
    "\n",
    "from utils.batch import *\n",
    "from utils.MPNN import *\n",
    "from utils.utils import *\n",
    "\n",
    "\n",
    "# parameters for train network\n",
    "\n",
    "def MPNNModel(atom_dim,\n",
    "    bond_dim,\n",
    "    batch_size=batch_size,\n",
    "    message_units=32,\n",
    "    message_steps=8,\n",
    "    num_attention_heads=16,\n",
    "    dense_units=dense_units):\n",
    "\n",
    "    atom_features = layers.Input((atom_dim), dtype=\"float32\", name=\"atom_features\")\n",
    "    bond_features = layers.Input((bond_dim), dtype=\"float32\", name=\"bond_features\")\n",
    "    pair_indices = layers.Input((2), dtype=\"int32\", name=\"pair_indices\")\n",
    "    molecule_indicator = layers.Input((), dtype=\"int32\", name=\"molecule_indicator\")\n",
    "\n",
    "    x = MessagePassing(message_units, message_steps)([atom_features, bond_features, pair_indices])\n",
    "    x = TransformerEncoderReadout(num_attention_heads, message_units, dense_units, batch_size)([x, molecule_indicator])\n",
    "    x = layers.Dense(50, activation=\"relu\")(x)\n",
    "    x = layers.Dense(tasks, activation=\"linear\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs=[atom_features, bond_features, pair_indices, molecule_indicator],\n",
    "        outputs=[x])\n",
    "    return model\n",
    "    \n",
    "\n",
    "\n",
    "optimizer = RMSprop(0.1)\n",
    "lr_metric = get_lr_metric(optimizer)   \n",
    "\n",
    "model = MPNNModel(atom_dim = X_train[0][0][0].shape[0], bond_dim = X_train[1][0][0].shape[0])\n",
    "model.compile(loss = regression_loss, metrics = [lr_metric])    \n",
    "model.summary()\n",
    "T.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0d0455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Early stopping parameters\n",
    "\n",
    "train_dataset = MPNNDataset(X_train, y_train, batch_size)\n",
    "val_dataset = MPNNDataset(X_val, y_val, batch_size)\n",
    "test_dataset = MPNNDataset(X_test, y_test, batch_size)\n",
    "\n",
    "callbacks_list = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00000001, verbose=1, mode='auto',cooldown=0),\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, mode='min', verbose=1)]\n",
    "\n",
    "# parameters for train network\n",
    "\n",
    "epochs=2000\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=val_dataset,                    \n",
    "                    callbacks=(callbacks_list))\n",
    "\n",
    "model.save_weights(\"./models/TM-MPNN_regression_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126deea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot model history\n",
    "\n",
    "hist = history.history\n",
    "\n",
    "plt.figure(figsize=(13, 9))\n",
    "\n",
    "\n",
    "for label in ['val_loss','loss']:\n",
    "    plt.subplot(221)\n",
    "    plt.plot(hist[label], label = label)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot( hist['lr'],hist['val_loss']  )\n",
    "plt.legend()\n",
    "plt.xlabel(\"lr\")\n",
    "plt.ylabel(\"val_loss\")\n",
    "    \n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                    wspace=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b491b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical characteristico of model without 3-sigma rule\n",
    "\n",
    "prediction_train = model.predict(train_dataset)\n",
    "prediction_val = model.predict(val_dataset)\n",
    "prediction_test = model.predict(test_dataset)\n",
    "\n",
    "\n",
    "for index1 in range(prediction_train.shape[1]):\n",
    "\n",
    "    train_pred = pd.DataFrame(y_train[:,index1],prediction_train[:,index1]) \n",
    "    train_pred['y_pred'] = train_pred.index\n",
    "    train_pred = train_pred.rename(columns = {0: 'y_obs'})\n",
    "    train_pred2 = train_pred.dropna()\n",
    "    train_pred2 = train_pred2.reset_index(drop=True)\n",
    "    train_pred2['Folds'] = 'Train'\n",
    "    train_pred2 = train_pred2.assign(Folds_error = abs(train_pred2['y_pred'] - train_pred2['y_obs']))\n",
    "    train_pred2['Folds error Mean'] = train_pred2['Folds_error'].mean() \n",
    "    train_pred2['Folds error 3*sigma'] = train_pred2['Folds_error'].std()\n",
    "    train_pred2['Folds error 3*sigma'] = train_pred2['Folds error 3*sigma']*3\n",
    "\n",
    "    for index2 in range(prediction_val.shape[1]):\n",
    "         \n",
    "        val_pred = pd.DataFrame(y_val[:,index2],prediction_val[:,index2])\n",
    "        val_pred['y_pred'] = val_pred.index\n",
    "        val_pred = val_pred.rename(columns = {0: 'y_obs'})\n",
    "        val_pred2 = val_pred.dropna()\n",
    "        val_pred2 = val_pred2.reset_index(drop=True)\n",
    "        val_pred2['Folds'] = 'val'\n",
    "        val_pred2 = val_pred2.assign(Folds_error = abs(val_pred2['y_pred'] - val_pred2['y_obs']))\n",
    "        val_pred2['Folds error Mean'] = val_pred2['Folds_error'].mean() \n",
    "        val_pred2['Folds error 3*sigma'] = val_pred2['Folds_error'].std()\n",
    "        val_pred2['Folds error 3*sigma'] = val_pred2['Folds error 3*sigma']*3\n",
    "           \n",
    "            \n",
    "        for index3 in range(prediction_test.shape[1]):\n",
    "         \n",
    "            test_pred = pd.DataFrame(y_test[:,index3],prediction_test[:,index3])\n",
    "            test_pred['y_pred'] = test_pred.index\n",
    "            test_pred = test_pred.rename(columns = {0: 'y_obs'})\n",
    "            test_pred2 = test_pred.dropna()\n",
    "            test_pred2 = test_pred2.reset_index(drop=True)\n",
    "            test_pred2['Folds'] = 'Test'\n",
    "            test_pred2 = test_pred2.assign(Folds_error = abs(test_pred2['y_pred'] - test_pred2['y_obs']))\n",
    "            test_pred2['Folds error Mean'] = test_pred2['Folds_error'].mean() \n",
    "            test_pred2['Folds error 3*sigma'] = test_pred2['Folds_error'].std()\n",
    "            test_pred2['Folds error 3*sigma'] = test_pred2['Folds error 3*sigma']*3\n",
    "\n",
    "            crossval_df = pd.concat([train_pred2, val_pred2, test_pred2], axis=0).reset_index(drop=True)\n",
    "\n",
    "\n",
    "            if index1 == index2 and index1 == index3:\n",
    "                    \n",
    "                r2  = (train_pred2[\"y_obs\"].corr(train_pred2[\"y_pred\"]))    \n",
    "                print((\"Results for task {} (train)\").format(index2+1))\n",
    "                print(\"r^2\\t%.2f\" % r2)\n",
    "                print (\"rmse\\t%.2f\" % sqrt(mean_squared_error(train_pred2[\"y_obs\"],train_pred2[\"y_pred\"])))\n",
    "                print (\"mse\\t%.2f\" % (mean_squared_error(train_pred2[\"y_obs\"],train_pred2[\"y_pred\"])))\n",
    "                print (\"mae\\t%.2f\"  %mean_absolute_error(train_pred2[\"y_obs\"],train_pred2[\"y_pred\"]))   \n",
    "\n",
    "                r2 = (val_pred2[\"y_obs\"].corr(val_pred2[\"y_pred\"]))\n",
    "                print((\"Results for task {} (validation)\").format(index3+1))\n",
    "                print(\"r^2\\t%.2f\" % r2)\n",
    "                print (\"rmse\\t%.2f\"  % sqrt(mean_squared_error(val_pred2[\"y_pred\"],val_pred2[\"y_obs\"])))\n",
    "                print (\"mse\\t%.2f\"  % (mean_squared_error(val_pred2[\"y_pred\"],val_pred2[\"y_obs\"])))\n",
    "                print (\"mae\\t%.2f\"  % mean_absolute_error(val_pred2[\"y_pred\"],val_pred2[\"y_obs\"]))\n",
    "                \n",
    "                r2 = (test_pred2[\"y_obs\"].corr(test_pred2[\"y_pred\"])) \n",
    "                print((\"Results for task {} (test)\").format(index1+1))\n",
    "                print(\"r^2\\t%.2f\" % r2)\n",
    "                print (\"rmse\\t%.2f\"  % sqrt(mean_squared_error(test_pred2[\"y_pred\"],test_pred2[\"y_obs\"]))) \n",
    "                print (\"mse\\t%.2f\"  % (mean_squared_error(test_pred2[\"y_pred\"],test_pred2[\"y_obs\"])))\n",
    "                print (\"mae\\t%.2f\"  % mean_absolute_error(test_pred2[\"y_pred\"],test_pred2[\"y_obs\"]))\n",
    "\n",
    "                g = sns.lmplot(x=\"y_pred\", y=\"y_obs\", hue=\"Folds\", data=crossval_df, fit_reg=False, height=7, \n",
    "                markers=[\"o\", \"o\", \"o\"], palette=\"rocket\",scatter_kws={\"s\": 50,'alpha':0.9},  aspect=30/30)\n",
    "                sns.regplot(x=\"y_pred\", y=\"y_obs\", data=crossval_df, scatter=False, ax=g.axes[0, 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7a541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Statistical characteristico of model using 3-sigma rule\n",
    "\n",
    "for index1 in range(prediction_train.shape[1]):\n",
    "\n",
    "    train_pred = pd.DataFrame(y_train[:,index1],prediction_train[:,index1]) \n",
    "    train_pred['y_pred'] = train_pred.index\n",
    "    train_pred = train_pred.rename(columns = {0: 'y_obs'})\n",
    "    train_pred2 = train_pred.dropna()\n",
    "    train_pred2 = train_pred2.reset_index(drop=True)\n",
    "    train_pred2['Folds'] = 'Train'\n",
    "    train_pred2 = train_pred2.assign(Folds_error = abs(train_pred2['y_pred'] - train_pred2['y_obs']))\n",
    "    train_pred2['Folds error Mean'] = train_pred2['Folds_error'].mean() \n",
    "    train_pred2['Folds error 3*sigma'] = train_pred2['Folds_error'].std()\n",
    "    train_pred2['Folds error 3*sigma'] = train_pred2['Folds error 3*sigma']*3\n",
    "    train_pred2=train_pred2[train_pred2['Folds_error']<=(train_pred2['Folds error 3*sigma'])] #keep only the ones that are within +3 to -3 standard deviations in the column 'Data'.\n",
    "\n",
    "    for index2 in range(prediction_val.shape[1]):\n",
    "         \n",
    "        val_pred = pd.DataFrame(y_val[:,index2],prediction_val[:,index2])\n",
    "        val_pred['y_pred'] = val_pred.index\n",
    "        val_pred = val_pred.rename(columns = {0: 'y_obs'})\n",
    "        val_pred2 = val_pred.dropna()\n",
    "        val_pred2 = val_pred2.reset_index(drop=True)\n",
    "        val_pred2['Folds'] = 'val'\n",
    "        val_pred2 = val_pred2.assign(Folds_error = abs(val_pred2['y_pred'] - val_pred2['y_obs']))\n",
    "        val_pred2['Folds error Mean'] = val_pred2['Folds_error'].mean() \n",
    "        val_pred2['Folds error 3*sigma'] = val_pred2['Folds_error'].std()\n",
    "        val_pred2['Folds error 3*sigma'] = val_pred2['Folds error 3*sigma']*3\n",
    "        val_pred2=val_pred2[val_pred2['Folds_error']<=(val_pred2['Folds error 3*sigma'])]#keep only the ones that are within +3 to -3 standard deviations in the column 'Data'.\n",
    "   \n",
    "        for index3 in range(prediction_test.shape[1]):\n",
    "\n",
    "            test_pred = pd.DataFrame(y_test[:,index3],prediction_test[:,index3])\n",
    "            test_pred['y_pred'] = test_pred.index\n",
    "            test_pred = test_pred.rename(columns = {0: 'y_obs'})\n",
    "            test_pred2 = test_pred.dropna()\n",
    "            test_pred2 = test_pred2.reset_index(drop=True)\n",
    "            test_pred2['Folds'] = 'Test'\n",
    "            test_pred2 = test_pred2.assign(Folds_error = abs(test_pred2['y_pred'] - test_pred2['y_obs']))\n",
    "            test_pred2['Folds error Mean'] = test_pred2['Folds_error'].mean() \n",
    "            test_pred2['Folds error 3*sigma'] = test_pred2['Folds_error'].std()\n",
    "            test_pred2['Folds error 3*sigma'] = test_pred2['Folds error 3*sigma']*3\n",
    "            test_pred2=test_pred2[test_pred2['Folds_error']<=(test_pred2['Folds error 3*sigma'])] #keep only the ones that are within +3 to -3 standard deviations in the column 'Data'.\n",
    "\n",
    "            crossval_df = pd.concat([train_pred2, val_pred2, test_pred2], axis=0).reset_index(drop=True)\n",
    "\n",
    "            if index1 == index2 and index1 == index3:\n",
    "                        \n",
    "                r2 = (train_pred2[\"y_obs\"].corr(train_pred2[\"y_pred\"]))    \n",
    "                print((\"Results for task {} (train)\").format(index2+1))\n",
    "                print(\"r^2\\t%.2f\" % r2)\n",
    "                print (\"rmse\\t%.2f\" % sqrt(mean_squared_error(train_pred2[\"y_obs\"],train_pred2[\"y_pred\"])))\n",
    "                print (\"mse\\t%.2f\" % (mean_squared_error(train_pred2[\"y_obs\"],train_pred2[\"y_pred\"])))\n",
    "                print (\"mae\\t%.2f\"  %mean_absolute_error(train_pred2[\"y_obs\"],train_pred2[\"y_pred\"]))   \n",
    "\n",
    "                r2= (val_pred2[\"y_obs\"].corr(val_pred2[\"y_pred\"]))\n",
    "                print((\"Results for task {} (validation)\").format(index3+1))\n",
    "                print(\"r^2\\t%.2f\" % r2)\n",
    "                print (\"rmse\\t%.2f\"  % sqrt(mean_squared_error(val_pred2[\"y_pred\"],val_pred2[\"y_obs\"])))\n",
    "                print (\"mse\\t%.2f\"  % (mean_squared_error(val_pred2[\"y_pred\"],val_pred2[\"y_obs\"])))\n",
    "                print (\"mae\\t%.2f\"  % mean_absolute_error(val_pred2[\"y_pred\"],val_pred2[\"y_obs\"]))\n",
    "                \n",
    "                r2 = (test_pred2[\"y_obs\"].corr(test_pred2[\"y_pred\"])) \n",
    "                print((\"Results for task {} (test)\").format(index1+1))\n",
    "                print(\"r^2\\t%.2f\" % r2)\n",
    "                print (\"rmse\\t%.2f\"  % sqrt(mean_squared_error(test_pred2[\"y_pred\"],test_pred2[\"y_obs\"]))) \n",
    "                print (\"mse\\t%.2f\"  % (mean_squared_error(test_pred2[\"y_pred\"],test_pred2[\"y_obs\"])))\n",
    "                print (\"mae\\t%.2f\"  % mean_absolute_error(test_pred2[\"y_pred\"],test_pred2[\"y_obs\"]))\n",
    "\n",
    "                g = sns.lmplot(x=\"y_pred\", y=\"y_obs\", hue=\"Folds\", data=crossval_df, fit_reg=False, height=7, \n",
    "                markers=[\"o\", \"o\", \"o\"], palette=\"rocket\",scatter_kws={\"s\": 50,'alpha':0.9},  aspect=30/30)\n",
    "                sns.regplot(x=\"y_pred\", y=\"y_obs\", data=crossval_df, scatter=False, ax=g.axes[0, 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c046a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0b86550ea44597804204a48b6097d9d9fddb827366e03432e7a68bfbd6f6c1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
